{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24f4b26",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd325d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    parameters received from papermill\n",
    "\n",
    "    these are the parameters that are passed to the script\n",
    "    above is the default values\n",
    "    they can be overridden by the user when running the script\n",
    "\"\"\"\n",
    "\n",
    "BASE_URL = \"https://www.gov.br/anp/pt-br\"\n",
    "B100_SALES = f\"{BASE_URL}/assuntos/distribuicao-e-revenda/comercializacao-de-biodiesel\"\n",
    "RAW_PATH = \"data/raw/b100_sales\"\n",
    "\n",
    "bucket_name = os.getenv(\"GOOGLE_BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get file download URL\n",
    "\"\"\"\n",
    "\n",
    "response = requests.get(B100_SALES, verify=False)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "if soup is None:\n",
    "    raise Exception(\"Failed to retrieve data from the URL.\")\n",
    "title_text = 'Volumes Comercializados de Biodiesel'\n",
    "title_h3 = soup.find('h3', string=title_text)\n",
    "jump_p = title_h3.find_next_sibling()\n",
    "jump_p = jump_p.find_next_sibling()\n",
    "year = jump_p.find_next_sibling()\n",
    "\n",
    "data_by_year = {}\n",
    "\n",
    "current_year = year.get_text(strip=True)\n",
    "data_by_year[current_year] = []\n",
    "\n",
    "next_elem = year.find_next_sibling()\n",
    "while next_elem:\n",
    "    if next_elem.name == 'ul':\n",
    "        for li in next_elem.find_all('li'):\n",
    "            a_tag = li.find('a')\n",
    "            if a_tag and 'href' in a_tag.attrs:\n",
    "                link = a_tag['href']\n",
    "                text = a_tag.get_text(strip=True)\n",
    "                li_text = li.get_text(strip=True)\n",
    "\n",
    "\n",
    "                start = li_text.find('Atualizado em ')\n",
    "                if start != -1:\n",
    "                    li_text = li_text[start + len('Atualizado em '):-1].strip()\n",
    "\n",
    "                data_by_year[current_year].append({'text': text, 'link': link, 'updated_date': li_text})\n",
    "            else:\n",
    "                print(\"Elemento <li> nÃ£o contÃ©m um link.\")\n",
    "        next_elem = next_elem.find_next_sibling()\n",
    "    else:\n",
    "        if next_elem.name == 'h3' and next_elem.get_text(strip=True).isdigit():\n",
    "            current_year = next_elem.get_text(strip=True)\n",
    "            if current_year not in data_by_year:\n",
    "                data_by_year[current_year] = []\n",
    "            next_elem = next_elem.find_next_sibling()\n",
    "            continue\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcaec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_years = {\n",
    "\t\"2023\",\n",
    "\t\"2024\",\n",
    "\t\"2025\"\n",
    "}\n",
    "all_dataframes = []\n",
    "for year in current_years:\n",
    "    if year in data_by_year and data_by_year[year]:\n",
    "        print(f\"Processing year: {year}\")\n",
    "        \n",
    "        download_url = data_by_year[year][0]['link']\n",
    "        response = requests.get(download_url, verify=False)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download file for year {year}: {response.status_code}\")\n",
    "            continue\n",
    "            \n",
    "        file_bytes = response.content\n",
    "        file_buffer = BytesIO(file_bytes)\n",
    "        \n",
    "        B100_BRONZE_COLUMNS_MAPPING = {\n",
    "            \"2023\": {\n",
    "                \"Mês/Ano\": \"vb100_dat_compra\",\n",
    "                \"Raiz\\nCNPJ\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social\": \"vb100_txt_razao_social\",\n",
    "                \"Quantidade\\nde Produto\\n(m³)\": \"vb100_qtd_volume\"\n",
    "            },\n",
    "            \"2024\": {\n",
    "                \"Data\": \"vb100_dat_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social do Distribuidor\": \"vb100_txt_razao_social\",\n",
    "                \"Razão Social do Produtor\": \"vb100_nom_produtor\",\n",
    "                \"CNPJ do Produtor\": \"vb100_num_produtor_cnpj\",\n",
    "                \"Volume (m3)\": \"vb100_qtd_volume\"\n",
    "            },\n",
    "            \"2025\": {\n",
    "                \"Data\": \"vb100_dat_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social do Distribuidor\": \"vb100_txt_razao_social\",\n",
    "                \"Razão Social do Produtor\": \"vb100_nom_produtor\",\n",
    "                \"CNPJ do Produtor\": \"vb100_num_produtor_cnpj\",\n",
    "                \"Volume (m3)\": \"vb100_qtd_volume\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        map_to_use = B100_BRONZE_COLUMNS_MAPPING.get(year, B100_BRONZE_COLUMNS_MAPPING[\"2024\"])\n",
    "        \n",
    "        try:\n",
    "            df_year = pd.read_excel(file_buffer, header=2, usecols=lambda x: 'Unnamed' not in x)\n",
    "            df_year = df_year.rename(columns=map_to_use)\n",
    "            \n",
    "            df_year['vb100_dat_compra'] = pd.to_datetime(df_year['vb100_dat_compra'], format='%Y%m')\n",
    "            df_year[\"vb100_num_cnpj\"] = df_year[\"vb100_num_cnpj\"].astype(str).str.zfill(8)\n",
    "            df_year['vb100_dat_compra'] = df_year['vb100_dat_compra'].dt.date\n",
    "            df_year['vb100_qtd_volume'] = df_year['vb100_qtd_volume'].astype(float)\n",
    "            df_year['vb100_dat_criacao'] = pd.Timestamp.now(tz='America/Sao_Paulo')\n",
    "            \n",
    "            if int(year) < 2024:\n",
    "                df_year[\"vb100_nom_produtor\"] = None\n",
    "                df_year[\"vb100_num_produtor_cnpj\"] = None\n",
    "            else:\n",
    "                df_year[\"vb100_num_produtor_cnpj\"] = df_year[\"vb100_num_produtor_cnpj\"].astype(str).str.zfill(14)\n",
    "            \n",
    "            all_dataframes.append(df_year)\n",
    "            print(f\"Successfully processed {len(df_year)} rows for year {year}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for year {year}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"No data found for year {year}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"Combined dataset has {len(df)} total rows\")\n",
    "else:\n",
    "    raise Exception(\"No data was processed for any year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    change columns data types\n",
    "\"\"\"\n",
    "\n",
    "df['vb100_dat_compra'] = pd.to_datetime(df['vb100_dat_compra'], format='%Y%m')\n",
    "df[\"vb100_num_cnpj\"] = df[\"vb100_num_cnpj\"].astype(str).str.zfill(8)\n",
    "df['vb100_dat_compra'] = df['vb100_dat_compra'].dt.date\n",
    "df['vb100_qtd_volume'] = df['vb100_qtd_volume'].astype(float)\n",
    "df['vb100_dat_criacao'] = pd.Timestamp.now(tz='America/Sao_Paulo')\n",
    "\n",
    "if int(current_year) < 2024:\n",
    "    df[\"vb100_nom_produtor\"] = None\n",
    "    df[\"vb100_num_produtor_cnpj\"] = None\n",
    "else:\n",
    "    df[\"vb100_num_produtor_cnpj\"] = df[\"vb100_num_produtor_cnpj\"].astype(str).str.zfill(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    insert data into BigQuery with date-based partitioning\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "bq_dataset = \"rw_ext_anp\"\n",
    "table_name = \"venda_b100\"\n",
    "\n",
    "table_id = f\"{project_id}.{bq_dataset}.{table_name}\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    ")\n",
    "\n",
    "partition_key = date.today().strftime('%Y%m%d')\n",
    "\n",
    "partitioned_table_id = f\"{table_id}${partition_key}\"\n",
    "print(f\"Inserting data for partition: {partition_key}\")\n",
    "print(f\"Total rows to insert: {len(df)}\")\n",
    "\n",
    "try:\n",
    "    job = client.load_table_from_dataframe(\n",
    "        df, partitioned_table_id, job_config=job_config\n",
    "    )\n",
    "    job.result()\n",
    "    print(f\"Data for {partition_key} inserted successfully.\")\n",
    "    \n",
    "    df['year'] = pd.to_datetime(df['vb100_dat_compra']).dt.year\n",
    "    summary = df.groupby('year').size()\n",
    "    print(\"Data summary by year:\")\n",
    "    for year, count in summary.items():\n",
    "        print(f\"  {year}: {count} rows\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error inserting data for {partition_key}: {str(e)}\")\n",
    "\n",
    "print(\"Data insertion completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomass-calc-automation-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
