{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24f4b26",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd325d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853c9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    parameters received from papermill\n",
    "\n",
    "    these are the parameters that are passed to the script\n",
    "    above is the default values\n",
    "    they can be overridden by the user when running the script\n",
    "\"\"\"\n",
    "\n",
    "BASE_URL = \"https://www.gov.br/anp/pt-br\"\n",
    "B100_SALES = f\"{BASE_URL}/assuntos/distribuicao-e-revenda/comercializacao-de-biodiesel\"\n",
    "RAW_PATH = \"data/raw/b100_sales\"\n",
    "\n",
    "bucket_name = os.getenv(\"GOOGLE_BUCKET_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267a7d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fnascime/labs_vibra/pipeline_extracts/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get file download URL\n",
    "\"\"\"\n",
    "\n",
    "response = requests.get(B100_SALES, verify=False)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "if soup is None:\n",
    "    raise Exception(\"Failed to retrieve data from the URL.\")\n",
    "title_text = 'Volumes Comercializados de Biodiesel'\n",
    "title_h3 = soup.find('h3', string=title_text)\n",
    "jump_p = title_h3.find_next_sibling()\n",
    "jump_p = jump_p.find_next_sibling()\n",
    "year = jump_p.find_next_sibling()\n",
    "\n",
    "data_by_year = {}\n",
    "\n",
    "current_year = year.get_text(strip=True)\n",
    "data_by_year[current_year] = []\n",
    "\n",
    "next_elem = year.find_next_sibling()\n",
    "while next_elem:\n",
    "    if next_elem.name == 'ul':\n",
    "        for li in next_elem.find_all('li'):\n",
    "            a_tag = li.find('a')\n",
    "            if a_tag and 'href' in a_tag.attrs:\n",
    "                link = a_tag['href']\n",
    "                text = a_tag.get_text(strip=True)\n",
    "                li_text = li.get_text(strip=True)\n",
    "\n",
    "\n",
    "                start = li_text.find('Atualizado em ')\n",
    "                if start != -1:\n",
    "                    li_text = li_text[start + len('Atualizado em '):-1].strip()\n",
    "\n",
    "                data_by_year[current_year].append({'text': text, 'link': link, 'updated_date': li_text})\n",
    "            else:\n",
    "                print(\"Elemento <li> nÃ£o contÃ©m um link.\")\n",
    "        next_elem = next_elem.find_next_sibling()\n",
    "    else:\n",
    "        if next_elem.name == 'h3' and next_elem.get_text(strip=True).isdigit():\n",
    "            current_year = next_elem.get_text(strip=True)\n",
    "            if current_year not in data_by_year:\n",
    "                data_by_year[current_year] = []\n",
    "            next_elem = next_elem.find_next_sibling()\n",
    "            continue\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cfcaec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year: 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fnascime/labs_vibra/pipeline_extracts/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data for year 2024: 'raiz_cnpj_distribuidor'\n",
      "Processing year: 2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fnascime/labs_vibra/pipeline_extracts/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2878 rows for year 2025\n",
      "Processing year: 2023\n",
      "Error processing data for year 2023: 'volume_m3'\n",
      "Combined dataset has 2878 total rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fnascime/labs_vibra/pipeline_extracts/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gov.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "current_years = {\n",
    "\t\"2023\",\n",
    "\t\"2024\",\n",
    "\t\"2025\"\n",
    "}\n",
    "all_dataframes = []\n",
    "for year in current_years:\n",
    "    if year in data_by_year and data_by_year[year]:\n",
    "        print(f\"Processing year: {year}\")\n",
    "\n",
    "        download_url = data_by_year[year][0]['link']\n",
    "        response = requests.get(download_url, verify=False)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download file for year {year}: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        file_bytes = response.content\n",
    "        file_buffer = BytesIO(file_bytes)\n",
    "\n",
    "        B100_BRONZE_COLUMNS_MAPPING = {\n",
    "            \"2023\": {\n",
    "                \"Mês/Ano\": \"vb100_dat_compra\",\n",
    "                \"Raiz\\nCNPJ\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social\": \"vb100_txt_razao_social\",\n",
    "                \"Quantidade\\nde Produto\\n(m³)\": \"vb100_qtd_volume\"\n",
    "            },\n",
    "            \"2024\": {\n",
    "                \"Data\": \"vb100_dat_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social do Distribuidor\": \"vb100_txt_razao_social\",\n",
    "                \"Razão Social do Produtor\": \"vb100_nom_produtor\",\n",
    "                \"CNPJ do Produtor\": \"vb100_num_produtor_cnpj\",\n",
    "                \"Volume (m3)\": \"vb100_qtd_volume\"\n",
    "            },\n",
    "            \"2025\": {\n",
    "                \"Data\": \"vb100_dat_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"vb100_num_cnpj\",\n",
    "                \"Razão Social do Distribuidor\": \"vb100_txt_razao_social\",\n",
    "                \"Razão Social do Produtor\": \"vb100_nom_produtor\",\n",
    "                \"CNPJ do Produtor\": \"vb100_num_produtor_cnpj\",\n",
    "                \"Volume (m3)\": \"vb100_qtd_volume\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        B100_BRONZE_COLUMNS_MAPPING = {\n",
    "            \"2023\": {\n",
    "                \"Mês/Ano\": \"data_compra\",\n",
    "                \"Raiz\\nCNPJ\": \"raiz_cnpj_distribuidor\",\n",
    "                \"Razão Social\": \"razao_social_distribuidor\",\n",
    "                \"Quantidade\\nde Produto\\n(m³)\": \"qtd_de_produto_m3\"\n",
    "            },\n",
    "            \"2024\": {\n",
    "                \"Data\": \"data_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"raiz_cnpj_distribuidor\",\n",
    "                \"Razão Social do Distribuidor\": \"razao_social_distribuidor\",\n",
    "                \"Razão Social do Produtor\": \"razao_social_produtor\",\n",
    "                \"CNPJ do Produtor\": \"cnpj_produtor\",\n",
    "                \"Volume (m3)\": \"volume_m3\"\n",
    "            },\n",
    "            \"2025\": {\n",
    "                \"Data\": \"data_compra\",\n",
    "                \"Raiz de CNPJ do Distribuidor\": \"raiz_cnpj_distribuidor\",\n",
    "                \"Razão Social do Distribuidor\": \"razao_social_distribuidor\",\n",
    "                \"Razão Social do Produtor\": \"razao_social_produtor\",\n",
    "                \"CNPJ do Produtor\": \"cnpj_produtor\",\n",
    "                \"Volume (m3)\": \"volume_m3\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        map_to_use = B100_BRONZE_COLUMNS_MAPPING.get(year, B100_BRONZE_COLUMNS_MAPPING[\"2024\"])\n",
    "\n",
    "        try:\n",
    "            df_year = pd.read_excel(file_buffer, header=2, usecols=lambda x: 'Unnamed' not in x)\n",
    "            df_year = df_year.rename(columns=map_to_use)\n",
    "\n",
    "            df_year['data_compra'] = pd.to_datetime(df_year['data_compra'], format='%Y%m')\n",
    "            df_year[\"raiz_cnpj_distribuidor\"] = df_year[\"raiz_cnpj_distribuidor\"].astype(str).str.zfill(8)\n",
    "            df_year['data_compra'] = df_year['data_compra'].dt.date\n",
    "            df_year['volume_m3'] = df_year['volume_m3'].astype(float)\n",
    "            df_year['data_criacao'] = pd.Timestamp.now(tz='America/Sao_Paulo')\n",
    "\n",
    "            if int(year) < 2024:\n",
    "                df_year[\"razao_social_produtor\"] = None\n",
    "                df_year[\"cnpj_produtor\"] = None\n",
    "            else:\n",
    "                df_year[\"cnpj_produtor\"] = df_year[\"cnpj_produtor\"].astype(str).str.zfill(14)\n",
    "\n",
    "            all_dataframes.append(df_year)\n",
    "            print(f\"Successfully processed {len(df_year)} rows for year {year}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for year {year}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"No data found for year {year}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"Combined dataset has {len(df)} total rows\")\n",
    "else:\n",
    "    raise Exception(\"No data was processed for any year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33bc03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    change columns data types\n",
    "\"\"\"\n",
    "\n",
    "df['data_compra'] = pd.to_datetime(df['data_compra'], format='%Y%m')\n",
    "df[\"raiz_cnpj_distribuidor\"] = df[\"raiz_cnpj_distribuidor\"].astype(str).str.zfill(8)\n",
    "df['data_compra'] = df['data_compra'].dt.date\n",
    "df['volume_m3'] = df['volume_m3'].astype(float)\n",
    "df['data_criacao'] = pd.Timestamp.now(tz='America/Sao_Paulo')\n",
    "\n",
    "if int(current_year) < 2024:\n",
    "    df[\"razao_social_produtor\"] = None\n",
    "    df[\"cnpj_produtor\"] = None\n",
    "else:\n",
    "    df[\"cnpj_produtor\"] = df[\"cnpj_produtor\"].astype(str).str.zfill(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff81c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data for partition: 20250716\n",
      "Total rows to insert: 2878\n",
      "Error inserting data for 20250716: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/None/datasets/rw_ext_anp/tables/venda_b100$20250716?prettyPrint=false: Invalid resource name projects/None; Project id: None\n",
      "Data insertion completed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    insert data into BigQuery with date-based partitioning\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "bq_dataset = \"rw_ext_anp\"\n",
    "table_name = \"venda_b100\"\n",
    "\n",
    "table_id = f\"{project_id}.{bq_dataset}.{table_name}\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
    ")\n",
    "\n",
    "partition_key = date.today().strftime('%Y%m%d')\n",
    "\n",
    "partitioned_table_id = f\"{table_id}${partition_key}\"\n",
    "print(f\"Inserting data for partition: {partition_key}\")\n",
    "print(f\"Total rows to insert: {len(df)}\")\n",
    "\n",
    "try:\n",
    "    job = client.load_table_from_dataframe(\n",
    "        df, partitioned_table_id, job_config=job_config\n",
    "    )\n",
    "    job.result()\n",
    "    print(f\"Data for {partition_key} inserted successfully.\")\n",
    "\n",
    "    df['year'] = pd.to_datetime(df['vb100_dat_compra']).dt.year\n",
    "    summary = df.groupby('year').size()\n",
    "    print(\"Data summary by year:\")\n",
    "    for year, count in summary.items():\n",
    "        print(f\"  {year}: {count} rows\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting data for {partition_key}: {str(e)}\")\n",
    "\n",
    "print(\"Data insertion completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
